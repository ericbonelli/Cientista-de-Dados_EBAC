{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfFSXUko0xOewrlSc5giYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericbonelli/Cientista-de-Dados_EBAC/blob/main/Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üå≥ Random Forest"
      ],
      "metadata": {
        "id": "-w76JuWKgUdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ 1. O que √© Random Forest?\n",
        "\n",
        "O **Random Forest** √© um algoritmo de aprendizado de m√°quina que constr√≥i v√°rias √°rvores de decis√£o diferentes e combina os resultados delas para fazer uma previs√£o final.\n",
        "\n",
        "A diferen√ßa principal em rela√ß√£o ao Bagging √© que o Random Forest **al√©m de fazer amostragem com reposi√ß√£o (bootstrap)**, tamb√©m **escolhe aleatoriamente apenas algumas features (colunas)** para cada √°rvore. Isso diminui a correla√ß√£o entre elas e aumenta a robustez do modelo.\n",
        "\n",
        "Como resultado, temos um modelo mais **preciso, est√°vel e resistente ao overfitting** do que uma √∫nica √°rvore de decis√£o.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "JRHLPTmkgijm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ‚úÖ 2. Passo a passo para o algoritmo Random Forest\n",
        "\n",
        "\n",
        "1. **Bootstrap**\n",
        "   - Criar v√°rias amostras com reposi√ß√£o a partir do conjunto de dados original.\n",
        "\n",
        "2. **Sele√ß√£o aleat√≥ria de features**\n",
        "   - Para cada √°rvore, escolher aleatoriamente um subconjunto de colunas (features) para treinar, o que gera √°rvores diferentes e menos correlacionadas.\n",
        "\n",
        "3. **Modelagem com Decision Trees**\n",
        "   - Treinar uma √°rvore de decis√£o em cada amostra com as features selecionadas.\n",
        "\n",
        "4. **Agrega√ß√£o**\n",
        "   - Combinar as previs√µes das √°rvores:\n",
        "     - Para classifica√ß√£o: usar vota√ß√£o (classe mais votada).\n",
        "     - Para regress√£o: usar a m√©dia das previs√µes.\n",
        "\n",
        "   ---"
      ],
      "metadata": {
        "id": "ldS7zCnXgswv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ 3. Qual a diferen√ßa entre Bagging e Random Forest?"
      ],
      "metadata": {
        "id": "BDZyI48Bod1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Caracter√≠stica              | **Bagging**                              | **Random Forest**                                 |\n",
        "|----------------------------|------------------------------------------|---------------------------------------------------|\n",
        "| Tipo de modelo base        | Qualquer (mas geralmente Decision Trees) | Apenas √Årvores de Decis√£o                        |\n",
        "| Bootstrap (amostragem)     | ‚úÖ Sim                                   | ‚úÖ Sim                                            |\n",
        "| Sele√ß√£o aleat√≥ria de features | ‚ùå N√£o (usa todas)                      | ‚úÖ Sim (subset aleat√≥rio por √°rvore)             |\n",
        "| Correla√ß√£o entre √°rvores   | Alta                                     | Baixa (por causa da sele√ß√£o de features)         |\n",
        "| Vota√ß√£o/M√©dia              | ‚úÖ Sim                                   | ‚úÖ Sim                                            |\n",
        "| Exemplo em sklearn         | `BaggingClassifier`                      | `RandomForestClassifier`                         |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6OmuxDPoohnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ 4. Implementa√ß√£o em Python\n",
        "\n",
        "Vamos usar o conjunto de dados Iris como exemplo e aplicar o Randon Farest, sendo demonstrando passo a passo de forma manual e depois usando scikit-learn\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aroFvdA8g551"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üå≥ 4.1. Random Forest com Dataset Iris - Manual\n",
        "\n",
        "Vamos entender o funcionamento do Randon forest recriando suas 4 etapas principais com o dataset Iris.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9ZeGybOtio5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìå Etapa 1: Bootstrap (amostragem com reposi√ß√£o)"
      ],
      "metadata": {
        "id": "Cpz7qHvhkxAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Carregar dataset Iris\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target)\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "# Dividir dados para teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "k339usHWi5LN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Etapa 2: Feature Selection (sele√ß√£o aleat√≥ria de colunas)"
      ],
      "metadata": {
        "id": "H8LWfeWKpyHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o para selecionar aleatoriamente k features\n",
        "def selecionar_features(X, k, random_state=None):\n",
        "    np.random.seed(random_state)\n",
        "    cols = np.random.choice(X.columns, size=k, replace=False)\n",
        "    return X[cols], cols"
      ],
      "metadata": {
        "id": "CUsMMmNup6kk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üå± Etapa 3: Treinar v√°rias √Årvores com subsets diferentes"
      ],
      "metadata": {
        "id": "JUKjM5Mwi8wK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "n_arvores = 10\n",
        "k_features = 2\n",
        "modelos = []\n",
        "colunas_usadas = []\n",
        "\n",
        "for i in range(n_arvores):\n",
        "    # Etapa 1: Bootstrap\n",
        "    X_sample, y_sample = resample(X_train, y_train, replace=True, random_state=i)\n",
        "\n",
        "    # Etapa 2: Feature Selection\n",
        "    X_sub, cols = selecionar_features(X_sample, k=k_features, random_state=i)\n",
        "\n",
        "    # Etapa 3: Modelagem\n",
        "    modelo = DecisionTreeClassifier(random_state=i)\n",
        "    modelo.fit(X_sub, y_sample)\n",
        "\n",
        "    modelos.append(modelo)\n",
        "    colunas_usadas.append(cols)"
      ],
      "metadata": {
        "id": "QaqpqeD_i_Kl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Etapa 4: Agrega√ß√£o das Previs√µes (Vota√ß√£o)\n"
      ],
      "metadata": {
        "id": "nvibPlZGjNY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Fazer previs√µes com as √°rvores\n",
        "previsoes = []\n",
        "\n",
        "for modelo, cols in zip(modelos, colunas_usadas):\n",
        "    X_test_sub = X_test[cols]\n",
        "    pred = modelo.predict(X_test_sub)\n",
        "    previsoes.append(pred)\n",
        "\n",
        "# Vota√ß√£o majorit√°ria\n",
        "previsoes = np.array(previsoes)\n",
        "final = mode(previsoes, axis=0, keepdims=True).mode[0]\n",
        "\n",
        "print(\"‚úÖ Acur√°cia do Random Forest manual:\", accuracy_score(y_test, final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6-MVLYwjPAB",
        "outputId": "19407b84-984d-4675-d93a-456ceb04698e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Acur√°cia do Random Forest manual: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö° 4.2. Random Forest com Scikit-learn (autom√°tico)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Xlu-mwBNj90I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregar dados\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Criar Random Forest com 10 √°rvores\n",
        "rf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Previs√£o e avalia√ß√£o\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"‚úÖ Acur√°cia com RandomForestClassifier:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlsdlCeFkT62",
        "outputId": "89b82142-e47d-407c-8b8b-c723725ce827"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Acur√°cia com RandomForestClassifier: 1.0\n"
          ]
        }
      ]
    }
  ]
}