{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericbonelli/Cientista-de-Dados_EBAC/blob/main/mod25_Tarefa01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGrI4XZfxh5W"
      },
      "source": [
        "# C√°lculo - Tarefa 01\n",
        "\n",
        "1. Marque quais desses m√©todos/algoritmos muito populares em ci√™ncia de dados s√£o baseados no uso de derivada:\n",
        "\n",
        "    1. M√©todo M√≠nimos Quadrados\n",
        "    2. Gradiente descendente\n",
        "    3. Newton Raphson\n",
        "    4. CART (√Årvore de decis√£o)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmos que Utilizam Derivadas em Ci√™ncia de Dados\n",
        "\n",
        "Abaixo est√£o alguns m√©todos populares em ci√™ncia de dados e a indica√ß√£o se utilizam **derivadas** em sua formula√ß√£o ou execu√ß√£o:\n",
        "\n",
        "| M√©todo/Algoritmo             | Usa Derivada? | Justificativa                                                                 |\n",
        "|-----------------------------|:-------------:|-------------------------------------------------------------------------------|\n",
        "| **M√©todo dos M√≠nimos Quadrados** | ‚úÖ Sim         | A vers√£o anal√≠tica envolve derivadas para minimizar a soma dos erros quadr√°ticos. |\n",
        "| **Gradiente Descendente**       | ‚úÖ Sim         | Utiliza o gradiente (vetor de derivadas parciais) para encontrar a dire√ß√£o de descida. |\n",
        "| **Newton-Raphson**             | ‚úÖ Sim         | Baseado na primeira e segunda derivadas (incluindo a Hessiana em casos multivariados). |\n",
        "| **CART (√Årvore de Decis√£o)**   | ‚ùå N√£o         | N√£o utiliza derivadas; baseia-se em parti√ß√µes de dados via medidas como Gini ou entropia. |\n",
        "\n",
        "### ‚úÖ M√©todos baseados em derivada:\n",
        "- M√©todo dos M√≠nimos Quadrados  \n",
        "- Gradiente Descendente  \n",
        "- Newton-Raphson\n",
        "\n",
        "### ‚ùå M√©todo que **n√£o** utiliza derivadas:\n",
        "- CART (√Årvore de Decis√£o)\n",
        "___"
      ],
      "metadata": {
        "id": "yP1QtgEexv7Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKsyyPalxh5h"
      },
      "source": [
        "2. Dada uma base de dados com uma vari√°vel resposta $y$ e um conjunto de vari√°veis explicativas. Considere uma estrutura de um modelo de regress√£o. Explique com suas palavras por que n√£o √© poss√≠vel obter par√¢metros que forne√ßam um erro quadr√°tico m√©dio (EQM) menor que o obtido com estimadores de m√≠nimos quadrados."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Quando usamos um modelo de regress√£o linear, queremos encontrar os melhores coeficientes para prever a vari√°vel resposta ùë¶. O m√©todo dos **m√≠nimos quadrados** faz isso da forma mais eficiente poss√≠vel, pois ele **escolhe os par√¢metros que deixam os erros (diferen√ßa entre o valor real e o previsto) o menor poss√≠vel ao quadrado**.\n",
        "\n",
        "Logo, n√£o d√° pra ter um EQM menor do que o que j√° √© obtido pelos m√≠nimos quadrados, pois esse m√©todo **foi feito justamente para isso: minimizar o erro m√©dio ao quadrado**. Ele √© o melhor poss√≠vel nesse sentido.\n",
        "\n"
      ],
      "metadata": {
        "id": "85UEdc3EyAjl"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "√çndice",
      "title_sidebar": "Conte√∫do",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}